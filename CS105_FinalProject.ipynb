{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aebacf88",
   "metadata": {},
   "source": [
    "First, we begin by taking in the dataset and cleaning it up for text mining and sentiment analysis. We will also create a new csv file with the clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc77a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset source: https://jmcauley.ucsd.edu/data/amazon/\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Json structure\n",
    "'''\n",
    "reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "asin - ID of the product, e.g. 0000013714\n",
    "reviewerName - name of the reviewer\n",
    "vote - helpful votes of the review\n",
    "style - a disctionary of the product metadata, e.g., \"Format\" is \"Hardcover\"\n",
    "reviewText - text of the review\n",
    "overall - rating of the product\n",
    "summary - summary of the review\n",
    "unixReviewTime - time of the review (unix time)\n",
    "reviewTime - time of the review (raw)\n",
    "image - images that users post after they have received the product\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a623c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reviews to all lowercase\n",
    "def to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "# Remove special characters from reviews\n",
    "def remove_special_char(text):\n",
    "    newString = ''\n",
    "    for i in text:\n",
    "        if i.isalnum():                     # If character is alphanumeric, keep. Else, add a space\n",
    "            newString = newString + i\n",
    "        else:\n",
    "            newString = newString + ' '\n",
    "    return newString\n",
    "\n",
    "# Remove stopwords: https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "def rem_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    newStr = \"\"\n",
    "    for w in words : \n",
    "        if w not in stop_words :\n",
    "            newStr += w + \" \"\n",
    "    #return [w for w in words if w not in stop_words]\n",
    "    return newStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromJson(filename) :\n",
    "    df = pd.read_json(filename, lines=True)\n",
    "    df = df.drop(columns=['verified','reviewTime','reviewerID','asin','vote','unixReviewTime','asin','reviewerName'])\n",
    "    df.reviewText = df.reviewText.apply(to_lower)\n",
    "    \n",
    "    df = df[df['reviewText'].str.split().str.len().gt(5)] # Reviews must have greater than 5 words to perform sentiment analysis\n",
    "\n",
    "    df.reviewText = df.reviewText.apply(remove_special_char)\n",
    "    \n",
    "    df.reviewText = df.reviewText.apply(rem_stopwords)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getDataFromJson('Movies_and_TV_5.json')\n",
    "\n",
    "# End of data cleaning, clean data set\n",
    "df.to_csv(\"clean_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ad757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use overall to classify as positive or negative: 3+ is positive, 1 and 2 are negative\n",
    "# reviewText is full review, will use for sentiment analysis\n",
    "# Summary might be useful for EDA? Length of summary with score maybe?\n",
    "# Style also for EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a014d",
   "metadata": {},
   "source": [
    "Now, we will perform EDA to better understand our data and find interesting information about our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488754dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "pdf = df['overall'].value_counts()\n",
    "pdf = pdf.reindex(sorted(pdf.index), axis = 1)\n",
    "pdf.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b698c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_df = df['style']\n",
    "format_df = df['style'].value_counts()\n",
    "format_df.plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8163ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.overall, df['style'].astype(str)).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb43df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# END OF EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VECTORIZING BAG OF WORDS\n",
    "df['review'] = df['summary'] + \" \" + df['reviewText']\n",
    "vectorizer.fit(df['review'])\n",
    "names = vectorizer.get_feature_names_out()\n",
    "bag_of_words = vectorizer.fit(df['review'])\n",
    "bag_of_words = vectorizer.transform(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c39ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bag_of_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19526321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USEFUL FUNCTIONS FOR BAG OF WORDS\n",
    "bag_of_words[0].indices\n",
    "bag_of_words[0].data\n",
    "vectorizer.vocabulary_.get(\"learn\")\n",
    "names[1361]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030afbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF TESTING, PROBABLY NOT USEFUL?\n",
    "tfidfVect = TfidfVectorizer()\n",
    "tfidf = tfidfVect.fit(df['review'])\n",
    "tfidf = tfidfVect.transform(df['review'])\n",
    "print(tfidf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15649be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity function seen in class\n",
    "def getSimilarity(review1, review2) :\n",
    "    r1 = review1.todense()\n",
    "    r2 = review2.todense()\n",
    "    r1 = np.squeeze(np.asarray(r1))\n",
    "    r2 = np.squeeze(np.asarray(r2))\n",
    "\n",
    "    return dot(r1, r2) / (norm(r1) * norm(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "getSimilarity(bag_of_words[0],bag_of_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af7f0d4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 19) (1958712002.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[35], line 19\u001b[1;36m\u001b[0m\n\u001b[1;33m    'ideal','innovative','intelligent','joy','joyful','laugh','laughing','legendary','lovely','love','marvelous','masterful','motivational','\u001b[0m\n\u001b[1;37m                                                                                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 19)\n"
     ]
    }
   ],
   "source": [
    "negWords = ['abysmal','adverse','alarming','angry','annoy','annoying','anxious','apathy','appalling','atrocious','awful','ass','bad',\n",
    "            'banal','barbed','belligerent','bemoan','beneath','boring','broken','callous','clumsy','coarse','cold','cold-hearted',\n",
    "            'collapse','confused','confusing','contradictory','contrary','corrosive','corrupt','creepy','criminal','cruel',\n",
    "            'damage','damaging','dastardly','dead','decaying','deformed','dumpster','deny','deplorable','depressed','deprived','despicable',\n",
    "            'detrimental','dirty','disease','disgusting','disheveled', 'disagree','dishonest','dishonorable','dismal','distress','dreadful',\n",
    "            'dreary','enraged','eroding','evil','fail', 'faulty', 'fear', 'feeble', 'filthy', 'foul', 'garbage','grave', 'greed', 'grim', \n",
    "            'gross', 'grotesque', 'gruesome', 'guilty','haggard', 'hard', 'harmful', 'hate', 'hideous', 'horrendous', 'horrible',\n",
    "            'hostile', 'hurt', 'hurtful','icky', 'ignorant', 'ignore', 'ill', 'immature', 'imperfect', 'inelegant', 'infernal',\n",
    "            'insidious', 'insipid','junky','lousy','mean','messy','monstrous','monstrosity','naive','nasty','negative','never','nonsense',\n",
    "           'offensive','oppressive','pain','painful','plain','poor','poison','poisonous','prejudice','questionable','quit','repulsive',\n",
    "           'rotten','rude','ruthless','sad','scary','shoddy','sick','sickening','sorry','stressful','suspicious','terrible','terrifying',\n",
    "           'ugly','undermine','unfair','unfavorable','unhappy','unhealthy','unjust','unlucky','unpleasant','unsatisfactory','unwanted',\n",
    "           'unwelcome','upset','vicious','vile','worthless','trash','trashcan', 'yuck', 'one','two']\n",
    "posWords = ['accepted','acclaimed','accomplishment','achievement','admire','adorable','agree','agreeable','amazing','angelic','appealing',\n",
    "           'approve','attractive','awesome','beautiful','best','bliss','brilliant','bubbly','celebrate','charming','cheery','classic','commend',\n",
    "           'cool','creative','cute','dazzling','delight','delightful','distinguished','ecstatic','electrifying','elegant','effective','echanting',\n",
    "           'encouraging','engaging','essential','esteemed','ethical','excellent','exciting','exquisite','fabulous','fair','fantastic','favorable',\n",
    "           'fine','fresh','friendly','fun','funny','genius','genuine','glamorous','good','gorgeous','great','happy','healthy','heavenly',\n",
    "           'ideal','innovative','intelligent','joy','joyful','laugh','laughing','legendary','lovely','love','marvelous','masterful','motivational',\n",
    "            'nice','perfect','phenomenal','pleasant','pleasureable','polished','positive','powerful','proud','refined','refreshing','rejoice','remarkable',\n",
    "           'respected','rewarding','right','safe','skilled','skillful','smile','soulful','special','stunning','success','successful','super','superb','terrific',\n",
    "            'thrilling','thriving','unreal','upbeat','valued','welcome','wholesome','wonderful','wondrous','worthy','wow', 'yay', 'three', 'four', 'five']\n",
    "\n",
    "def classify(index) :\n",
    "    i = 0\n",
    "    ratings = []\n",
    "    #Weighting/amount of positive scores\n",
    "    posScores = 0\n",
    "    #Weighting/amount of negative scores\n",
    "    negScores = 0\n",
    "    # the mean rating of the k nearest neighbors\n",
    "    avgRating = 0\n",
    "    \n",
    "    # Neighbor class we will use for knn\n",
    "    class neighbor :\n",
    "        def __init__(self):\n",
    "            self.index = -1\n",
    "            self.distance = -1\n",
    "        def __eq__(self, other) :\n",
    "            if(self.distance == other.distance) :\n",
    "                return True\n",
    "            else :\n",
    "                return False\n",
    "        def __lt__(self, other) :\n",
    "            if(self.distance < other.distance) :\n",
    "                return True\n",
    "            else :\n",
    "                return False\n",
    "        def __gt__(self, other) :\n",
    "            if(self.distance > other.distance) :\n",
    "                return True\n",
    "            else :\n",
    "                return False\n",
    "\n",
    "    # Get all similarity scores\n",
    "    neighbors = []\n",
    "    for review in df['review'] :\n",
    "        if i == index :\n",
    "            i += 1\n",
    "            continue\n",
    "        sim = getSimilarity(bag_of_words[index], bag_of_words[i])\n",
    "        #minimum similarity threshold\n",
    "        if sim > 0.10 :\n",
    "            # Create neighbor object that we can sort the similarity of and only take the k nearest ones\n",
    "            curNeighbor = neighbor()\n",
    "            curNeighbor.index = i\n",
    "            curNeighbor.distance = sim\n",
    "            neighbors.append(curNeighbor)\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    # Get data from knn\n",
    "    knn = sorted(neighbors)\n",
    "    k = 201\n",
    "    \n",
    "    #iterator for k\n",
    "    curK = 0\n",
    "    for neighbor in knn :\n",
    "        if curK >= k :\n",
    "            break\n",
    "        curRating = df.iloc[neighbor.index]['overall']\n",
    "        #print(\"Rating: \", curRating)\n",
    "        ratings.append(curRating)\n",
    "        # If neighbor has < 3 rating, add negative score weight\n",
    "        if curRating < 3.0 :\n",
    "            #weighted knn\n",
    "            #negScores += pow(sim,1/2) + 0.1\n",
    "            negScores += 1\n",
    "        # otherwise add positive score weight\n",
    "        else :\n",
    "            #weighted knn\n",
    "            #posScores += pow(sim,1/2) + 0.1\n",
    "            posScores += 1\n",
    "        curK += 1\n",
    "    \n",
    "    print(\"True rating \", df.iloc[index]['overall'])\n",
    "    print(\"Pos scores: \", posScores)\n",
    "    print(\"Neg scores: \", negScores)\n",
    "    #print(\"Scores array : \", ratings)\n",
    "    avgRating = np.mean(ratings)\n",
    "    print(\"Avg rating : \", avgRating)\n",
    "    # Algorithm for determining classification, given the meanscore and ratio of positive to negative similar reviews\n",
    "    if avgRating >= 2.5 : \n",
    "        if posScores > negScores or abs(posScores - negScores) <= 1 :\n",
    "            return 1\n",
    "        else :\n",
    "            return -1\n",
    "    else :\n",
    "        if posScores < negScores or abs(posScores - negScores) <= 1 :\n",
    "            return -1\n",
    "        else : \n",
    "            return 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6835de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f252cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave one out validator\n",
    "i = 0\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "for review in df['review'] :\n",
    "    print(\"Index \", i)\n",
    "    trueRating = df.iloc[i]['overall']\n",
    "    ratingType = 1\n",
    "\n",
    "    if trueRating < 3.0 :\n",
    "        ratingType = -1\n",
    "    predicted = classify(i)\n",
    "    print(\"Predicted: \", predicted)\n",
    "    if ratingType == predicted :\n",
    "        #print(\"Correct classification!\")\n",
    "        correct += 1\n",
    "    else :\n",
    "        print(\"Wrong classification\")\n",
    "        incorrect += 1\n",
    "    i += 1\n",
    "print(\"Correct: \", correct, \" Incorrect: \", incorrect)\n",
    "accuracy = correct / (correct + incorrect)\n",
    "print(\"Accuracy: \",  accuracy)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
